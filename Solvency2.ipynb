{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Repository SFCR Template Information 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('Data Repository SFCR Template Information 2023.csv')  # Adjust this to your dataset\n",
    "\n",
    "# Step 1: Data Preprocessing\n",
    "pivot_data = data.pivot_table(\n",
    "    index=['InstitutionName', 'ReportingDate', 'InstitutionType'],\n",
    "    columns='row_full_name',\n",
    "    values='Euro_value_or_percentage_value',\n",
    "    aggfunc='first'\n",
    ").reset_index()\n",
    "\n",
    "pivot_data = pivot_data.dropna(subset=['Assets    Total assets', 'Liabilities    Total liabilities'])\n",
    "\n",
    "# Step 2: Feature Engineering\n",
    "pivot_data['Asset_Liability_Ratio'] = pivot_data['Assets    Total assets'] / pivot_data['Liabilities    Total liabilities']\n",
    "pivot_data['Target'] = np.where(pivot_data['Asset_Liability_Ratio'] < 1.2, 1, 0)\n",
    "pivot_data['Cash_to_Assets'] = pivot_data['Assets    Cash and cash equivalents'] / pivot_data['Assets    Total assets']\n",
    "pivot_data['Excess_to_Assets'] = pivot_data.get('Excess of assets over liabilities', 0) / pivot_data['Assets    Total assets']\n",
    "\n",
    "print(\"Target Distribution:\\n\", pivot_data['Target'].value_counts())\n",
    "if pivot_data['Target'].nunique() < 2:\n",
    "    raise ValueError(\"Target variable has only one class.\")\n",
    "\n",
    "# Step 3: Handle Missing Values and Encoding\n",
    "numerical_cols = pivot_data.select_dtypes(include=[np.number]).columns\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "pivot_data[numerical_cols] = imputer.fit_transform(pivot_data[numerical_cols])\n",
    "\n",
    "le = LabelEncoder()\n",
    "pivot_data['InstitutionType_Encoded'] = le.fit_transform(pivot_data['InstitutionType'])\n",
    "\n",
    "# Step 4: Feature Selection (exclude Asset_Liability_Ratio to prevent leakage)\n",
    "feature_cols = [\n",
    "    'Assets    Total assets', 'Liabilities    Total liabilities',\n",
    "    'Assets    Cash and cash equivalents', 'Assets    Investments (other than assets held for index-linked and unit-linked contracts)',\n",
    "    'Liabilities    Technical provisions - non-life', 'Cash_to_Assets',\n",
    "    'Excess_to_Assets', 'InstitutionType_Encoded'\n",
    "]\n",
    "X = pivot_data[feature_cols]\n",
    "y = pivot_data['Target']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Step 5: Model Setup\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, class_weight='balanced'),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced'),\n",
    "    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),\n",
    "    'SVM': SVC(kernel='rbf', random_state=42, class_weight='balanced'),\n",
    "    'Neural Network': MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=500, random_state=42)\n",
    "}\n",
    "\n",
    "# Step 6: Cross-Validation and Evaluation\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    # Use 5-fold cross-validation\n",
    "    accuracy = cross_val_score(model, X_scaled, y, cv=5, scoring='accuracy').mean()\n",
    "    precision = cross_val_score(model, X_scaled, y, cv=5, scoring='precision').mean()\n",
    "    recall = cross_val_score(model, X_scaled, y, cv=5, scoring='recall').mean()\n",
    "    f1 = cross_val_score(model, X_scaled, y, cv=5, scoring='f1').mean()\n",
    "    results[name] = {\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1\n",
    "    }\n",
    "\n",
    "# Step 7: Compare Results\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(\"\\nModel Comparison (Cross-Validation):\\n\", results_df)\n",
    "\n",
    "# Train-test split for detailed report and feature importance\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"\\nClassification Report for {name}:\\n\", classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "# Step 8: Feature Importance (Random Forest)\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
    "rf_model.fit(X_train, y_train)\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "print(\"\\nRandom Forest Feature Importance:\\n\", feature_importance)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importance)\n",
    "plt.title('Feature Importance from Random Forest')\n",
    "plt.show()\n",
    "\n",
    "# Step 9: Prediction on New Data\n",
    "new_data = pd.DataFrame({\n",
    "    'Assets    Total assets': [50000000],\n",
    "    'Liabilities    Total liabilities': [45000000],\n",
    "    'Assets    Cash and cash equivalents': [5000000],\n",
    "    'Assets    Investments (other than assets held for index-linked and unit-linked contracts)': [30000000],\n",
    "    'Liabilities    Technical provisions - non-life': [35000000],\n",
    "    'Cash_to_Assets': [5000000 / 50000000],\n",
    "    'Excess_to_Assets': [5000000 / 50000000],\n",
    "    'InstitutionType_Encoded': [le.transform(['Insurance Company Non-Life'])[0]]\n",
    "})\n",
    "new_data_scaled = scaler.transform(new_data[X.columns])\n",
    "\n",
    "print(\"\\nPredictions for New Data (0 = Stable, 1 = At Risk):\")\n",
    "for name, model in models.items():\n",
    "    model.fit(X_scaled, y)  # Fit on full data for prediction\n",
    "    pred = model.predict(new_data_scaled)\n",
    "    print(f\"{name}: {pred[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
